{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32dfc871",
   "metadata": {},
   "source": [
    "Custom ResNet18 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209fe300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c71bee",
   "metadata": {},
   "source": [
    "Set data directory, wanted batch size and the number of epochs for the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef71f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"Dataset\"\n",
    "batchSize = 16\n",
    "numEpochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7addb018",
   "metadata": {},
   "source": [
    "Try to utilizes CUDA-cores for training, otherwise the CPU will be used. The path for the model is also determined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b09b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"resnet18_screw_classifier.pth\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92379e28",
   "metadata": {},
   "source": [
    "The imagetransformation is defined and the images will be resized to 224x224, as ResNet18 was trained on that size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a19232",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67777429",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(os.path.join(dataDir, \"train\"), transform=transform)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(dataDir, \"val\"), transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchSize, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batchSize, shuffle=False, num_workers=4)\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "print(\"Classes:\", train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ce7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Get some random training images from your custom dataset\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Show images as a grid\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a33f6b6",
   "metadata": {},
   "source": [
    "The model is loaded/downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8867f2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc284e4",
   "metadata": {},
   "source": [
    "With the model loaded, the training of the ResNet18 model using the images taken can be initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1209143",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ----- TRAINING LOOP -----\n",
    "print(\"Training...\")\n",
    "for epoch in range(numEpochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}/{numEpochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86652afb",
   "metadata": {},
   "source": [
    "When the model i trained, the validation images will be used to find the accuracy of the ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd4730",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Store for confusion matrix\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0acca48",
   "metadata": {},
   "source": [
    "To visualize the class prediction a confusion matrix is made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde91ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_dataset.classes)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix - Validation Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c11561",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d325067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), modelPath)\n",
    "print(f\"Model saved to {modelPath}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
