{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4dd2716",
   "metadata": {},
   "source": [
    "**Image preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00494964",
   "metadata": {},
   "source": [
    "Firstly all libaries will be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81981267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe50f175",
   "metadata": {},
   "source": [
    "Define input and output folders for the processed and cropped images so the images can be prepared for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e3624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folders = [\"Raw/Plaster\", \"Raw/Machine\", \"Raw/Philips\", \"Raw/Torx\"]\n",
    "output_folders = [\"Threshholds/Plaster\", \"Threshholds/Machine\", \"Threshholds/Philips\", \"Threshholds/Torx\"]\n",
    "dataset_train = [\"Dataset/train/Plaster\", \"Dataset/train/Machine\", \"Dataset/train/Philips\", \"Dataset/train/Torx\"]\n",
    "dataset_val = [\"Dataset/val/Plaster\", \"Dataset/val/Machine\", \"Dataset/val/Philips\", \"Dataset/val/Torx\"]\n",
    "\n",
    "for folder in output_folders + dataset_train + dataset_val:\n",
    "    os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68633b06",
   "metadata": {},
   "source": [
    "When all the output folders are created, the kernel used for blob dilation will be defined. Here it is important to use a odd-number for dilation size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((9,9), np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c6694",
   "metadata": {},
   "source": [
    "With the dilation kernel defined, each image will be processed using grayscale, gaussian blue, dilation and will be cropped from the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_folder, output_folder, dataset_train, dataset_val in zip(input_folders, output_folders, dataset_train, dataset_val):\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith((\".jpg\")):\n",
    "\n",
    "            # Read the image from the dataset\n",
    "            img_path = os.path.join(input_folder, filename)\n",
    "            img = cv.imread(img_path)\n",
    "\n",
    "            # Convert the image to grayscale\n",
    "            gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Apply Gaussian blur before thresholding\n",
    "            blurred = cv.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "            # Apply a threshold to create a blob on the subject\n",
    "            _, thresh = cv.threshold(blurred, 65, 255, cv.THRESH_BINARY_INV)\n",
    "\n",
    "            # The dilation will be applied to ensure all parts of the screw remains\n",
    "            dilated = cv.dilate(thresh, kernel, iterations=2)\n",
    "\n",
    "            # Using contours, the blobs are detected\n",
    "            contours, _ = cv.findContours(dilated, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Crop size\n",
    "            crop_size = 256\n",
    "            half_crop = crop_size // 2\n",
    "\n",
    "            for i, contour in enumerate(contours):\n",
    "                x, y, w, h = cv.boundingRect(contour)\n",
    "\n",
    "                # Calculate the midpoint of the blob\n",
    "                center_x = x + w // 2\n",
    "                center_y = y + h // 2\n",
    "\n",
    "                # Midpoint centering\n",
    "                x_start = max(center_x - half_crop, 0)\n",
    "                y_start = max(center_y - half_crop, 0)\n",
    "\n",
    "                # Ensure the image boundaries aren't exceeded\n",
    "                x_end = min(x_start + crop_size, img.shape[1])\n",
    "                y_end = min(y_start + crop_size, img.shape[0])\n",
    "                x_start = max(x_end - crop_size, 0)\n",
    "                y_start = max(y_end - crop_size, 0)\n",
    "\n",
    "                # Crop\n",
    "                cropped = img[y_start:y_end, x_start:x_end]\n",
    "\n",
    "                # Save the cropped image\n",
    "                cropped_filename = f\"{filename.split('.')[0]}_crop_{i}.png\"\n",
    "                \n",
    "                if random.random() < 0.8:\n",
    "                    cropped_path = os.path.join(dataset_train, cropped_filename)\n",
    "                else:\n",
    "                    cropped_path = os.path.join(dataset_val, cropped_filename)\n",
    "            \n",
    "                cv.imwrite(cropped_path, cropped)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
